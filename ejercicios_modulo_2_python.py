# -*- coding: utf-8 -*-
"""Ejercicios Modulo 2 PYTHON.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1m87Qzzt2MEieGte0Lx3tuISvJ_TFObGB
"""

# 3. Realiza un histograma con las localizaciones donde Sheldon dice exclusivamente “Penny.”. Representa junto al anterior histograma otro con las localizaciones donde Sheldon dice algún texto que contenga “Penny” (podrías utilizar el método de pandas Series.str.contains).

import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_csv('big_bang_theory_dataset (1).csv')

# Filtrar las filas donde Sheldon dice exclusivamente "Penny."
sheldon_penny_only = df[(df['Speaker'] == 'Sheldon') & (df['Text'] == 'Penny.')]

# Filtrar las filas donde Sheldon dice cualquier texto que contenga "Penny"
sheldon_contains_penny = df[(df['Speaker'] == 'Sheldon') & (df['Text'].str.contains('Penny', case=False, na=False))]

# Crear histogramas de las localizaciones para ambos casos
plt.figure(figsize=(14, 6))

# Histograma para las veces que Sheldon dice exclusivamente "Penny."
plt.subplot(1, 2, 1)
plt.hist(sheldon_penny_only['Location'].dropna(), bins=10, edgecolor='black')  # Excluimos valores NaN
plt.title("Localizaciones donde Sheldon dice exclusivamente 'Penny.'")
plt.xlabel("Localización")
plt.ylabel("Frecuencia")
plt.xticks(rotation=45, ha='right')

# Histograma para las veces que Sheldon menciona "Penny" en cualquier contexto
plt.subplot(1, 2, 2)
plt.hist(sheldon_contains_penny['Location'].dropna(), bins=10, edgecolor='black')  # Excluimos valores NaN
plt.title("Localizaciones donde Sheldon menciona 'Penny'")
plt.xlabel("Localización")
plt.ylabel("Frecuencia")
plt.xticks(rotation=45, ha='right')

# Ajustar el layout para evitar superposiciones
plt.tight_layout()
plt.show()

# 4. (2 punto) Usando matplotlib. Representa las localizaciones de la escena en el eje Y y el personaje que habla en el eje X.

# Importamos las bibliotecas necesarias
import pandas as pd
import matplotlib.pyplot as plt

# Eliminar las filas donde 'Speaker' o 'Location' son nulos
df = df.dropna(subset=['Speaker', 'Location'])

# Seleccionar solo las 10 localizaciones más frecuentes para simplificar el gráfico
top_locations = df['Location'].value_counts().nlargest(10).index
df_top_locations = df[df['Location'].isin(top_locations)]

# Crear un gráfico de conteo utilizando un gráfico de barras agrupado
plt.figure(figsize=(14, 8))
df_top_locations.groupby(['Speaker', 'Location']).size().unstack().plot(kind='bar', stacked=True, ax=plt.gca())

# Configurar de etiquetas y título
plt.title("Frecuencia de diálogos por Localización y Personaje")
plt.xlabel("Personaje")
plt.ylabel("Frecuencia de diálogos")
plt.xticks(rotation=45, ha='right')

# Ajustar el layout
plt.tight_layout()
plt.show()

# 5. (2 punto) Agrupa el conjunto de datos por la temporada y el personaje. Para cada grupo genera una columna con el número de veces que se pronuncia la palabra “Penny” y otra columna con un índice para el grupo creado por personaje y temporada (podrías utilizar el método de pandas ngroup). Usando sklearn, realiza una regresión logística que relacione el número de veces que se dice “Penny” en una temporada con el personaje que lo dice.

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, classification_report

df = pd.read_csv('big_bang_theory_dataset (1).csv')

# Contar "Penny" en la columna 'Text' (sin distinción de mayúsculas)
df['Penny_Count'] = df['Text'].str.lower().str.count('penny').fillna(0).astype(int)

# Agrupar por temporada y personaje, y sumar las veces que se menciona "Penny"
grouped_data = df.groupby(['Season', 'Speaker']).agg({'Penny_Count': 'sum'}).reset_index()

# Añadir índice de grupo para cada combinación de temporada y personaje
grouped_data['Group_Index'] = grouped_data.groupby(['Season', 'Speaker']).ngroup()

# Codificar los personajes a valores numéricos
label_encoder = LabelEncoder()
grouped_data['Speaker_Encoded'] = label_encoder.fit_transform(grouped_data['Speaker'])

# Definir las características y el objetivo
X = grouped_data[['Penny_Count']]
y = grouped_data['Speaker_Encoded']

# Dividir en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Entrenar el modelo de regresión logística
log_reg = LogisticRegression(random_state=42)
log_reg.fit(X_train, y_train)

# Hacer predicciones y evaluar el modelo
y_pred = log_reg.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred, target_names=label_encoder.classes_)

print("Accuracy:", accuracy)
print("Classification Report:\n", report)